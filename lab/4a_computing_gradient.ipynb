{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing gradient\n",
    "\n",
    "Training DNNs requires computing gradient of the loss with respect to the parameters, and this is topic of this notebook.\n",
    "\n",
    "Your task will be to:\n",
    "\n",
    "* Implement Evolution Search training of DNNs that does not require backpropagation\n",
    "* Implement all forward and backward functions for a MLP with custom activation function\n",
    "\n",
    "Goal is to:\n",
    "\n",
    "* Introduce ingredients necessary to train NN:\n",
    "    * model\n",
    "    * loss\n",
    "    * optimizer\n",
    "* Introduce different ways of computing or estimating $\\frac{\\partial{L(w)}}{{\\partial w}}$\n",
    "* Get understanding of Evolution Search and Backpropagation algorithms\n",
    "\n",
    "Exam:\n",
    "\n",
    "* For exam you are expected to understand how backpropagation works. Questions might refer to implementation details in PyTorch. See also Resources section for a good video about backpropgation, and how it is implemented in PyTorch.\n",
    "\n",
    "What's (probably) next:\n",
    "\n",
    "* Go through each component of the training loop:\n",
    "    * (Lab 5) Neural Networks practical, part 1: architecture, understanding what is learned\n",
    "    * (Lab 6, ?) Neural Networks practical part 2: setting up data and loss\n",
    "    * (Lab 7, ?) Neural Networks practical part 3: optimization\n",
    "* (Lab 8, ?) On gradients's properties (e.g. adversarial examples, vanishing/exploding gradient, variance)\n",
    "\n",
    "Resources:\n",
    "\n",
    "* Backprop with focus on PyTorch: https://www.youtube.com/watch?v=ma2KXWblllc (see also other lectures from this series)\n",
    "\n",
    "* Evolution Search https://eng.uber.com/deep-neuroevolution/, https://arxiv.org/abs/1712.06564"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD requires $\\frac{\\partial L (w) }{\\partial w}$!\n",
    "\n",
    "<p>\n",
    "<font size=5>\n",
    "$$\\frac{\\partial L (w) }{\\partial w} = \\frac{1}{K} \\sum_{i=1}^{K} \\frac{\\partial L (x_i, w) }{\\partial w}$$\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<img width=600 src=\"https://github.com/gmum/nn2018/raw/master/lab/fig/3/sgd.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['lines.linewidth'] = 2\n",
    "mpl.rcParams['figure.figsize'] = (7, 7)\n",
    "mpl.rcParams['axes.titlesize'] = 12\n",
    "mpl.rcParams['axes.labelsize'] = 12\n",
    "\n",
    "# Get FashionMNIST (see 1b_FMNIST.ipynb for data exploration)\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Logistic regression needs 2D data\n",
    "x_train = x_train.reshape(-1, 784)\n",
    "x_test = x_test.reshape(-1, 784)\n",
    "\n",
    "# 0-1 normalization\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "\n",
    "# Convert to Torch Tensor. Just to avoid boilerplate code later\n",
    "x_train = torch.from_numpy(x_train).type(torch.FloatTensor)\n",
    "x_test = torch.from_numpy(x_test).type(torch.FloatTensor)\n",
    "y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "y_test = torch.from_numpy(y_test).type(torch.LongTensor)\n",
    "\n",
    "# Use only first 1k examples. Just for notebook to run faster\n",
    "x_train, y_train = x_train[0:1000], y_train[0:1000]\n",
    "x_test, y_test = x_test[0:1000], y_test[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop in PyTorch\n",
    "\n",
    "In this section we walk through implementation of traditional training loop  in PyTorch.\n",
    "\n",
    "Necessary ingredients train NN:\n",
    "    * model\n",
    "    * loss\n",
    "    * optimizer\n",
    "    \n",
    "<img width=600 src=\"https://github.com/gmum/nn2018/raw/master/lab/fig/4/smoothie.png\">\n",
    "\n",
    "Ref:\n",
    "\n",
    "https://github.com/vinhkhuc/PyTorch-Mini-Tutorials/blob/master/3_neural_net.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model(input_dim, output_dim, nonlinearity_module=torch.nn.Sigmoid, weight_module=torch.nn.Linear):\n",
    "    model = torch.nn.Sequential()\n",
    "    model.add_module(\"linear_1\", weight_module(input_dim, 512, bias=False))\n",
    "    model.add_module(\"sigmoid_1\", nonlinearity_module())\n",
    "    model.add_module(\"linear_2\", weight_module(512, output_dim, bias=False))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sgd_step(model, loss, x_val, y_val, lr=0.1, momentum=0.9):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "    \n",
    "    x = Variable(x_val, requires_grad=False)\n",
    "    y = Variable(y_val, requires_grad=False)\n",
    "\n",
    "    # Reset gradient\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward\n",
    "    fx = model.forward(x)\n",
    "    output = loss.forward(fx, y)\n",
    "\n",
    "    # Backward\n",
    "    output.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    return output.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, x_val):\n",
    "    x = Variable(x_val, requires_grad=False)\n",
    "    output = model.forward(x)\n",
    "    return output.data.numpy().argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(model, loss, step_fnc):\n",
    "    torch.manual_seed(42)\n",
    "    n_examples, n_features = x_train.size()\n",
    "    n_classes = 10\n",
    "    batch_size = 100\n",
    "\n",
    "    for i in tqdm.tqdm(range(100), total=100):\n",
    "        cost = 0.\n",
    "        num_batches = n_examples // batch_size\n",
    "        for k in range(num_batches):\n",
    "            start, end = k * batch_size, (k + 1) * batch_size\n",
    "            cost += sgd_step(model, loss, x_train[start:end], y_train[start:end])\n",
    "        predY = predict(model, x_test)\n",
    "        print((\"Epoch %d, cost = %f, acc = %.2f%%\"\n",
    "              % (i + 1, cost / num_batches, 100. * np.mean(predY == y_test.numpy()))))\n",
    "        \n",
    "    return np.mean(predY == y_test.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:00<00:10,  9.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, cost = 2.324177, acc = 9.70%\n",
      "Epoch 2, cost = 2.293060, acc = 9.50%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/100 [00:00<00:10,  9.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3, cost = 2.282423, acc = 11.50%\n",
      "Epoch 4, cost = 2.272841, acc = 14.40%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 4/100 [00:00<00:10,  9.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5, cost = 2.263336, acc = 16.20%\n",
      "Epoch 6, cost = 2.253844, acc = 17.00%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 6/100 [00:00<00:09,  9.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7, cost = 2.244350, acc = 18.00%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 7/100 [00:00<00:09,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8, cost = 2.234838, acc = 18.90%\n",
      "Epoch 9, cost = 2.225296, acc = 19.80%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 9/100 [00:00<00:08, 10.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10, cost = 2.215710, acc = 22.00%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 10/100 [00:00<00:08, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11, cost = 2.206069, acc = 24.10%\n",
      "Epoch 12, cost = 2.196363, acc = 26.70%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 12/100 [00:01<00:08,  9.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13, cost = 2.186582, acc = 29.50%\n",
      "Epoch 14, cost = 2.176716, acc = 31.50%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 14/100 [00:01<00:08, 10.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15, cost = 2.166757, acc = 33.40%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 15/100 [00:01<00:08,  9.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16, cost = 2.156700, acc = 35.40%\n",
      "Epoch 17, cost = 2.146536, acc = 37.00%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 17/100 [00:01<00:07, 10.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18, cost = 2.136263, acc = 37.90%\n",
      "Epoch 19, cost = 2.125874, acc = 38.80%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 19/100 [00:01<00:07, 10.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20, cost = 2.115367, acc = 39.40%\n",
      "Epoch 21, cost = 2.104739, acc = 40.70%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 21/100 [00:02<00:07, 11.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22, cost = 2.093988, acc = 41.60%\n",
      "Epoch 23, cost = 2.083115, acc = 41.70%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 23/100 [00:02<00:07, 10.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24, cost = 2.072119, acc = 42.50%\n",
      "Epoch 25, cost = 2.061003, acc = 42.70%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 25/100 [00:02<00:06, 10.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26, cost = 2.049766, acc = 43.30%\n",
      "Epoch 27, cost = 2.038414, acc = 43.90%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 27/100 [00:02<00:06, 10.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28, cost = 2.026948, acc = 44.60%\n",
      "Epoch 29, cost = 2.015374, acc = 45.80%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 29/100 [00:02<00:06, 10.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30, cost = 2.003698, acc = 46.30%\n",
      "Epoch 31, cost = 1.991924, acc = 46.60%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 31/100 [00:02<00:06, 10.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32, cost = 1.980059, acc = 46.80%\n",
      "Epoch 33, cost = 1.968112, acc = 47.20%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 33/100 [00:03<00:05, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34, cost = 1.956088, acc = 47.40%\n",
      "Epoch 35, cost = 1.943997, acc = 47.70%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 35/100 [00:03<00:05, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36, cost = 1.931846, acc = 48.00%\n",
      "Epoch 37, cost = 1.919645, acc = 48.20%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 37/100 [00:03<00:05, 11.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38, cost = 1.907402, acc = 48.30%\n",
      "Epoch 39, cost = 1.895128, acc = 48.20%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 39/100 [00:03<00:05, 11.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40, cost = 1.882831, acc = 48.50%\n",
      "Epoch 41, cost = 1.870520, acc = 48.60%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 41/100 [00:03<00:05, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 42, cost = 1.858206, acc = 49.10%\n",
      "Epoch 43, cost = 1.845897, acc = 49.50%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 43/100 [00:03<00:04, 11.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 44, cost = 1.833603, acc = 50.00%\n",
      "Epoch 45, cost = 1.821332, acc = 50.00%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 45/100 [00:04<00:04, 12.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 46, cost = 1.809094, acc = 50.20%\n",
      "Epoch 47, cost = 1.796897, acc = 50.20%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 47/100 [00:04<00:04, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 48, cost = 1.784750, acc = 50.70%\n",
      "Epoch 49, cost = 1.772660, acc = 50.80%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 49/100 [00:04<00:04, 12.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50, cost = 1.760634, acc = 50.70%\n",
      "Epoch 51, cost = 1.748681, acc = 51.20%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 51/100 [00:04<00:03, 12.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 52, cost = 1.736806, acc = 51.30%\n",
      "Epoch 53, cost = 1.725015, acc = 51.90%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 53/100 [00:04<00:03, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 54, cost = 1.713316, acc = 52.40%\n",
      "Epoch 55, cost = 1.701713, acc = 52.50%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 55/100 [00:04<00:03, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 56, cost = 1.690210, acc = 52.60%\n",
      "Epoch 57, cost = 1.678813, acc = 52.90%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 57/100 [00:05<00:03, 12.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 58, cost = 1.667526, acc = 53.40%\n",
      "Epoch 59, cost = 1.656352, acc = 53.90%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 59/100 [00:05<00:03, 12.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 60, cost = 1.645295, acc = 53.90%\n",
      "Epoch 61, cost = 1.634357, acc = 54.20%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 61/100 [00:05<00:03, 12.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 62, cost = 1.623542, acc = 54.30%\n",
      "Epoch 63, cost = 1.612850, acc = 54.60%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 63/100 [00:05<00:02, 12.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 64, cost = 1.602284, acc = 55.10%\n",
      "Epoch 65, cost = 1.591846, acc = 55.30%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|██████▌   | 65/100 [00:05<00:02, 12.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 66, cost = 1.581536, acc = 55.50%\n",
      "Epoch 67, cost = 1.571356, acc = 55.70%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 67/100 [00:05<00:02, 13.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 68, cost = 1.561306, acc = 55.90%\n",
      "Epoch 69, cost = 1.551386, acc = 56.30%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 69/100 [00:06<00:02, 13.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 70, cost = 1.541596, acc = 56.30%\n",
      "Epoch 71, cost = 1.531937, acc = 56.40%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|███████   | 71/100 [00:06<00:02, 12.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 72, cost = 1.522408, acc = 56.60%\n",
      "Epoch 73, cost = 1.513009, acc = 57.10%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 73/100 [00:06<00:02, 12.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 74, cost = 1.503739, acc = 57.10%\n",
      "Epoch 75, cost = 1.494597, acc = 57.20%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 75/100 [00:06<00:01, 13.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 76, cost = 1.485582, acc = 57.40%\n",
      "Epoch 77, cost = 1.476693, acc = 57.50%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 77/100 [00:06<00:01, 12.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 78, cost = 1.467930, acc = 57.60%\n",
      "Epoch 79, cost = 1.459290, acc = 58.10%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████▉  | 79/100 [00:06<00:01, 13.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 80, cost = 1.450773, acc = 58.30%\n",
      "Epoch 81, cost = 1.442377, acc = 58.40%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████  | 81/100 [00:06<00:01, 13.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 82, cost = 1.434100, acc = 58.40%\n",
      "Epoch 83, cost = 1.425942, acc = 58.40%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 83/100 [00:07<00:01, 12.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 84, cost = 1.417899, acc = 58.80%\n",
      "Epoch 85, cost = 1.409972, acc = 59.00%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 85/100 [00:07<00:01, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 86, cost = 1.402158, acc = 59.10%\n",
      "Epoch 87, cost = 1.394455, acc = 59.30%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|████████▋ | 87/100 [00:07<00:00, 13.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 88, cost = 1.386862, acc = 59.40%\n",
      "Epoch 89, cost = 1.379377, acc = 59.70%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 89/100 [00:07<00:00, 13.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 90, cost = 1.371997, acc = 59.70%\n",
      "Epoch 91, cost = 1.364723, acc = 59.80%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 91/100 [00:07<00:00, 13.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 92, cost = 1.357551, acc = 60.00%\n",
      "Epoch 93, cost = 1.350480, acc = 60.10%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 93/100 [00:07<00:00, 13.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 94, cost = 1.343508, acc = 60.20%\n",
      "Epoch 95, cost = 1.336634, acc = 60.30%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 95/100 [00:08<00:00, 12.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 96, cost = 1.329855, acc = 60.50%\n",
      "Epoch 97, cost = 1.323171, acc = 60.60%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 97/100 [00:08<00:00, 12.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 98, cost = 1.316578, acc = 60.70%\n",
      "Epoch 99, cost = 1.310077, acc = 61.00%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▉| 99/100 [00:08<00:00, 12.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100, cost = 1.303664, acc = 61.10%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.611"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(n_features, n_classes)\n",
    "loss = torch.nn.CrossEntropyLoss(size_average=True)\n",
    "train(step_fnc=sgd_step, loss=loss, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating $\\frac{\\partial L (w) }{\\partial w}$\n",
    "\n",
    "In this section we will implement different gradient computation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite Difference\n",
    "<p>\n",
    "<font size=4>\n",
    "Assuming we know direction we want to optimize in, we can approximate derivative simply by calculating\n",
    "\n",
    "$$\\langle \\frac{\\partial L (w) }{\\partial w}, \\vec{v} \\rangle \\approx \\frac{L(w) - L(w + v)}{|\\vec{v}|}$$\n",
    "\n",
    "\n",
    ", where $L(w)$ denotes esimation of loss (e.g. over whole training set, over $5\\%$ etc.). \n",
    "\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution Search\n",
    "\n",
    "<p>\n",
    "Intuitively, Evolution Search (ES) approximates gradient by computing multiple times finite difference. Importantly it works for non-differentiable costs as well.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<font size=4>\n",
    "$$ \\frac{\\partial L (w) }{\\partial w} \\approx \\frac{1}{N \\sigma^2} \\sum \\vec{v} L(w + \\vec{v})$$\n",
    "\n",
    "\n",
    ", where $\\epsilon$ is a normally distributed vector sampled from gauss of standard deviation $\\sigma$, and $L(w)$ denotes esimation of loss (e.g. over whole training set, over $5\\%$ etc.). \n",
    "\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<font size=4>\n",
    "Note: while it is recommended to not use minibatching in ES, for simplicity we will.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_model_weights(model):\n",
    "    params = model.state_dict()\n",
    "    p_order = [p[0] for p in model.named_parameters()]\n",
    "    return np.concatenate([params[w].cpu().numpy().reshape(-1, ) for w in p_order])\n",
    "    \n",
    "def set_model_weights(model, w):\n",
    "    params = model.state_dict()  \n",
    "    p_order = [p[0] for p in model.named_parameters()]\n",
    "    id = 0\n",
    "    for p in p_order:\n",
    "        shape = params[p].shape\n",
    "        D = np.prod(shape)\n",
    "        params[p].copy_(torch.from_numpy(w[id:id + D].reshape(shape)))\n",
    "        id += D\n",
    "        \n",
    "def L(w, loss, batch_size=10, x_tr=x_train, y_tr=y_train):\n",
    "    set_model_weights(model, w)\n",
    "    cost = 0.\n",
    "    n_examples, n_features = x_tr.size()\n",
    "    num_batches = n_examples // batch_size\n",
    "    for k in range(num_batches): \n",
    "        start, end = k * batch_size, (k + 1) * batch_size\n",
    "        x = Variable(x_tr[start:end], requires_grad=False)\n",
    "        y = Variable(y_tr[start:end], requires_grad=False)\n",
    "        fx = model.forward(x)\n",
    "        cost += loss.forward(fx, y)\n",
    "    return cost.data.numpy()[0] / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sgd_step(model, loss, x_val, y_val, lr, momentum):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    \n",
    "    x = Variable(x_val, requires_grad=False)\n",
    "    y = Variable(y_val, requires_grad=False)\n",
    "\n",
    "    # Reset gradient\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward\n",
    "    fx = model.forward(x)\n",
    "    output = loss.forward(fx, y)\n",
    "\n",
    "    # Backward\n",
    "    output.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    return output.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ES_grad(model, loss, x_tr, y_tr, sigma=0.001, N=100):\n",
    "    grad = 0\n",
    "    init_w = get_model_weights(model)\n",
    "    rng = np.random.RandomState(777)\n",
    "    for _ in range(N):\n",
    "        v = rng.normal(size=(len(init_w,)), scale=sigma)\n",
    "        set_model_weights(model, init_w + v)\n",
    "        reward = L(w=init_w + v, loss=loss, x_tr=x_tr, y_tr=y_tr)\n",
    "        grad += v * reward\n",
    "    set_model_weights(model, init_w)\n",
    "    return grad / (N * sigma**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ES_step(model, loss, x_tr, y_tr, lr):\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ------\n",
    "    model: torch.nn.Model\n",
    "        Model to take optimization step on\n",
    "    loss: torch.nn.Module\n",
    "        Loss function to optimize\n",
    "    x_tr: torch.Tensor, (n_examples, n_features)\n",
    "        Batch to compute gradient over\n",
    "    y_tr: torch.Tensor, (n_examples, )\n",
    "        Batch to compute gradient over\n",
    "    lr: float\n",
    "        Learning rate to use\n",
    "    \"\"\"\n",
    "    grad = ES_grad(model=model, loss=loss, x_tr=x_tr, y_tr=y_tr, sigma=)\n",
    "    set_model_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-251.85761036, -424.38760101, 1255.30842047, ..., -592.70242856,\n",
       "        652.9320004 , 1009.17007192])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ES_grad(model, loss, x_tr=x_train, y_tr=y_train, sigma=0.001, N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = build_model(784, 10)\n",
    "loss = torch.nn.CrossEntropyLoss(size_average=True)\n",
    "init_w = get_model_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3300431823730468"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "1.00000e-02 *\n",
       " 0.9429  3.2923  3.1312  ...   1.3594 -0.2681  3.9460\n",
       " 3.1556 -0.4204  2.5779  ...  -4.0802 -0.2860 -0.3668\n",
       "-1.9587  0.5703 -4.1915  ...  -3.7700  0.6600 -3.0861\n",
       "          ...             ⋱             ...          \n",
       " 4.0039  2.2218  1.1179  ...   2.5937 -0.4478 -0.9402\n",
       "-0.8708 -2.9625  1.9891  ...  -2.6581  0.0744 -3.0522\n",
       "-1.5492  2.2387 -0.6655  ...  -1.5889  0.7705 -4.3341\n",
       "[torch.FloatTensor of size 10x512]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sgd_step(model, loss, x_val, y_val, lr, momentum):\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    \n",
    "    x = Variable(x_val, requires_grad=False)\n",
    "    y = Variable(y_val, requires_grad=False)\n",
    "\n",
    "    # Reset gradient\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward\n",
    "    fx = model.forward(x)\n",
    "    output = loss.forward(fx, y)\n",
    "\n",
    "    # Backward\n",
    "    output.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    return output.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement own module\n",
    "\n",
    "PyTorch enable defining own Modules. Here we will implement Linear and ReQu modules ourselves, to understand better how backpropagation works. \n",
    "\n",
    "Below you can find an example Module implementing the classial ReLU nonlinearity.\n",
    "\n",
    "Ref: https://github.com/jcjohnson/pytorch-examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyReLU(torch.autograd.Function):\n",
    "  \"\"\"\n",
    "  We can implement our own custom autograd Functions by subclassing\n",
    "  torch.autograd.Function and implementing the forward and backward passes\n",
    "  which operate on Tensors.\n",
    "  \"\"\"\n",
    "  def forward(self, input):\n",
    "    \"\"\"\n",
    "    In the forward pass we receive a Tensor containing the input and return a\n",
    "    Tensor containing the output. You can cache arbitrary Tensors for use in the\n",
    "    backward pass using the save_for_backward method.\n",
    "    \"\"\"\n",
    "    self.save_for_backward(input)\n",
    "    return input.clamp(min=0)\n",
    "\n",
    "  def backward(self, grad_output):\n",
    "    \"\"\"\n",
    "    In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "    with respect to the output, and we need to compute the gradient of the loss\n",
    "    with respect to the input.\n",
    "    \"\"\"\n",
    "    input, = self.saved_tensors\n",
    "    grad_input = grad_output.clone()\n",
    "    grad_input[input < 0] = 0\n",
    "    return grad_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Linear module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement “ReQU” unit\n",
    "\n",
    "<p>\n",
    "<font size=4>\n",
    "Here, we’ll implement a made-up activation function that we’ll call the Rectified Quadratic Unit\n",
    "(ReQU). Like the sigmoid and ReLU and several others, it is applied element-wise to all its\n",
    "inputs:\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<font size=4>\n",
    "$$z_i = I[x_i > 0] x_i ^ 2$$\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "(Note, exercise is taken from  https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/practicals/practical4.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__main__.MyReLU is not a Module subclass",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-260974860282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonlinearity_module\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMyReLU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_fnc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msgd_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-151-e4a237304abc>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(input_dim, output_dim, nonlinearity_module, weight_module)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"linear_1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sigmoid_1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonlinearity_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"linear_2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kudkudak/anaconda/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36madd_module\u001b[0;34m(self, name, module)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             raise TypeError(\"{} is not a Module subclass\".format(\n\u001b[0;32m--> 113\u001b[0;31m                 torch.typename(module)))\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __main__.MyReLU is not a Module subclass"
     ]
    }
   ],
   "source": [
    "model = build_model(n_features, n_classes, nonlinearity_module=MyReLU)\n",
    "loss = torch.nn.CrossEntropyLoss(size_average=True)\n",
    "train(step_fnc=sgd_step, loss=loss, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement backpropagation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement custom activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement backward traversal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
